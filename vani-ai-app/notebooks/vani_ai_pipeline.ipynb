{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ™ï¸ Vani AI - Hinglish Podcast Generator\n",
        "\n",
        "**Transform any Wikipedia article into a natural-sounding Hinglish podcast conversation.**\n",
        "\n",
        "This notebook implements a complete pipeline that:\n",
        "1. Fetches and cleans Wikipedia article content\n",
        "2. Generates a conversational Hinglish script using LLM (Gemini/OpenAI)\n",
        "3. Synthesizes multi-speaker audio using ElevenLabs TTS\n",
        "4. Produces a final MP3 podcast file\n",
        "\n",
        "---\n",
        "\n",
        "## Table of Contents\n",
        "1. [Environment Setup](#1-environment-setup)\n",
        "2. [Wikipedia Content Extraction](#2-wikipedia-content-extraction)\n",
        "3. [Hinglish Script Generation](#3-hinglish-script-generation)\n",
        "4. [Text-to-Speech Synthesis](#4-text-to-speech-synthesis)\n",
        "5. [Audio Processing & Assembly](#5-audio-processing--assembly)\n",
        "6. [Output & Playback](#6-output--playback)\n",
        "7. [Prompting Strategy Explanation](#7-prompting-strategy-explanation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Environment Setup\n",
        "\n",
        "### 1.1 Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (including groq for fallback LLM)\n",
        "!pip install -q requests beautifulsoup4 wikipedia-api pydub elevenlabs google-generativeai openai groq\n",
        "\n",
        "# Install audio processing libraries for professional mastering\n",
        "!pip install -q pyloudnorm pedalboard\n",
        "\n",
        "# Install ffmpeg for audio processing (required by pydub)\n",
        "!apt-get install -qq ffmpeg\n",
        "\n",
        "print(\"âœ… All dependencies installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "from typing import List, Dict, Optional, Literal\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "from getpass import getpass\n",
        "\n",
        "# Web scraping\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import wikipediaapi\n",
        "\n",
        "# LLM providers\n",
        "import google.generativeai as genai\n",
        "from openai import OpenAI\n",
        "\n",
        "# TTS\n",
        "from elevenlabs import ElevenLabs\n",
        "\n",
        "# Audio processing\n",
        "from pydub import AudioSegment\n",
        "import pyloudnorm as pyln\n",
        "from pedalboard import Pedalboard, Compressor, Distortion, Gain\n",
        "\n",
        "# Colab display\n",
        "from IPython.display import Audio, display, Markdown, HTML\n",
        "\n",
        "print(\"âœ… All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 Configure API Keys\n",
        "\n",
        "Enter your API keys securely. You'll need:\n",
        "- **Gemini API Key** (from [Google AI Studio](https://aistudio.google.com/app/apikey)) - for script generation\n",
        "- **ElevenLabs API Key** (from [ElevenLabs](https://elevenlabs.io/)) - for TTS\n",
        "- **OpenAI API Key** (optional, from [OpenAI](https://platform.openai.com/)) - alternative LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# API Key Configuration\n",
        "# You can either set these as environment variables or enter them when prompted\n",
        "\n",
        "def get_api_key(name: str, env_var: str) -> str:\n",
        "    \"\"\"Get API key from environment or prompt user.\"\"\"\n",
        "    key = os.environ.get(env_var)\n",
        "    if not key:\n",
        "        key = getpass(f\"Enter your {name}: \")\n",
        "    return key\n",
        "\n",
        "# Get API keys\n",
        "GEMINI_API_KEY = get_api_key(\"Gemini API Key\", \"GEMINI_API_KEY\")\n",
        "ELEVENLABS_API_KEY = get_api_key(\"ElevenLabs API Key\", \"ELEVENLABS_API_KEY\")\n",
        "\n",
        "# Optional: Groq API Key for fallback (press Enter to skip)\n",
        "GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\", \"\")\n",
        "if not GROQ_API_KEY:\n",
        "    user_input = getpass(\"Enter your Groq API Key for fallback (press Enter to skip): \")\n",
        "    GROQ_API_KEY = user_input if user_input else None\n",
        "\n",
        "# Optional: OpenAI API Key (press Enter to skip)\n",
        "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
        "if not OPENAI_API_KEY:\n",
        "    user_input = getpass(\"Enter your OpenAI API Key (press Enter to skip): \")\n",
        "    OPENAI_API_KEY = user_input if user_input else None\n",
        "\n",
        "# Validate required keys\n",
        "assert GEMINI_API_KEY, \"âŒ Gemini API Key is required!\"\n",
        "assert ELEVENLABS_API_KEY, \"âŒ ElevenLabs API Key is required!\"\n",
        "\n",
        "print(\"âœ… API keys configured!\")\n",
        "print(f\"   - Gemini (primary): {'âœ“' if GEMINI_API_KEY else 'âœ—'}\")\n",
        "print(f\"   - Groq (fallback): {'âœ“' if GROQ_API_KEY else 'âœ— (skipped)'}\")\n",
        "print(f\"   - ElevenLabs: {'âœ“' if ELEVENLABS_API_KEY else 'âœ—'}\")\n",
        "print(f\"   - OpenAI: {'âœ“ (optional)' if OPENAI_API_KEY else 'âœ— (skipped)'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4 Initialize API Clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Primary: Gemini 2.5 Flash (best for natural, varied conversations)\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "gemini_model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "# Fallback: Groq (LLaMA 3.3 70B) - used if Gemini hits rate limits\n",
        "from groq import Groq\n",
        "groq_client = Groq(api_key=GROQ_API_KEY) if GROQ_API_KEY else None\n",
        "\n",
        "# Initialize ElevenLabs for TTS (primary and only TTS provider)\n",
        "elevenlabs_client = ElevenLabs(api_key=ELEVENLABS_API_KEY)\n",
        "\n",
        "# Initialize OpenAI (if available, for script generation only)\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None\n",
        "\n",
        "print(\"âœ… API clients initialized!\")\n",
        "print(f\"   - Primary LLM: Gemini 2.5 Flash\")\n",
        "print(f\"   - Fallback LLM: {'Groq (LLaMA 3.3 70B)' if groq_client else 'None'}\")\n",
        "print(f\"   - TTS Provider: ElevenLabs (eleven_multilingual_v2)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.5 Data Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ScriptLine:\n",
        "    \"\"\"A single line of dialogue in the script.\"\"\"\n",
        "    speaker: Literal[\"Rahul\", \"Anjali\"]\n",
        "    text: str\n",
        "\n",
        "@dataclass\n",
        "class PodcastScript:\n",
        "    \"\"\"Complete podcast script with title and dialogue.\"\"\"\n",
        "    title: str\n",
        "    script: List[ScriptLine]\n",
        "    source_url: str\n",
        "\n",
        "class LLMProvider(Enum):\n",
        "    \"\"\"Supported LLM providers.\"\"\"\n",
        "    GEMINI = \"gemini\"    # Primary: Gemini 2.0 Flash (best variety)\n",
        "    GROQ = \"groq\"        # Fallback: LLaMA 3.3 70B via Groq\n",
        "    OPENAI = \"openai\"    # Alternative: GPT-4\n",
        "\n",
        "print(\"âœ… Data models defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Wikipedia Content Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_article_title(url: str) -> str:\n",
        "    \"\"\"Extract article title from Wikipedia URL.\"\"\"\n",
        "    patterns = [\n",
        "        r'/wiki/([^#?]+)',  # Standard format\n",
        "        r'title=([^&]+)',   # Old format with query params\n",
        "    ]\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, url)\n",
        "        if match:\n",
        "            return match.group(1)\n",
        "    raise ValueError(f\"Could not extract article title from URL: {url}\")\n",
        "\n",
        "\n",
        "def fetch_wikipedia_content(url: str) -> Dict[str, str]:\n",
        "    \"\"\"Fetch and clean Wikipedia article content.\"\"\"\n",
        "    article_title = extract_article_title(url)\n",
        "    \n",
        "    wiki = wikipediaapi.Wikipedia(\n",
        "        user_agent='VaniAI/1.0 (Hinglish Podcast Generator)',\n",
        "        language='en'\n",
        "    )\n",
        "    \n",
        "    page = wiki.page(article_title)\n",
        "    \n",
        "    if not page.exists():\n",
        "        raise ValueError(f\"Wikipedia article not found: {article_title}\")\n",
        "    \n",
        "    return {\n",
        "        'title': page.title,\n",
        "        'content': page.text,\n",
        "        'summary': page.summary\n",
        "    }\n",
        "\n",
        "\n",
        "def clean_wikipedia_text(text: str, max_words: int = 3000) -> str:\n",
        "    \"\"\"Clean and truncate Wikipedia text for LLM processing.\"\"\"\n",
        "    # Remove reference markers [1], [2], etc.\n",
        "    text = re.sub(r'\\[\\d+\\]', '', text)\n",
        "    \n",
        "    # Remove unwanted sections\n",
        "    sections_to_remove = [\n",
        "        r'\\n== See also ==.*',\n",
        "        r'\\n== References ==.*',\n",
        "        r'\\n== External links ==.*',\n",
        "        r'\\n== Notes ==.*',\n",
        "        r'\\n== Further reading ==.*',\n",
        "    ]\n",
        "    for pattern in sections_to_remove:\n",
        "        text = re.sub(pattern, '', text, flags=re.DOTALL)\n",
        "    \n",
        "    # Remove multiple newlines\n",
        "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
        "    \n",
        "    # Truncate to max words\n",
        "    words = text.split()\n",
        "    if len(words) > max_words:\n",
        "        text = ' '.join(words[:max_words]) + '...'\n",
        "    \n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "print(\"âœ… Wikipedia extraction functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Hinglish Script Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The Hinglish Script Generation Prompt\n",
        "# Enhanced with few-shot examples from training scripts\n",
        "\n",
        "HINGLISH_SCRIPT_PROMPT = \"\"\"\n",
        "You are creating a natural 90-second Hinglish podcast conversation about the following content.\n",
        "\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "SOURCE CONTENT\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "{article_content}\n",
        "\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "SPEAKERS\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "ANJALI = Lead anchor / Expert\n",
        "â”œâ”€ Confident, articulate, well-prepared\n",
        "â”œâ”€ Explains topics clearly with enthusiasm\n",
        "â”œâ”€ Guides the conversation smoothly\n",
        "â””â”€ Shares interesting facts and insights\n",
        "\n",
        "RAHUL = Co-host / Sidekick  \n",
        "â”œâ”€ Energetic, curious, adds humor\n",
        "â”œâ”€ Asks smart follow-up questions\n",
        "â”œâ”€ Has his own perspectives (not just agreeing)\n",
        "â””â”€ Keeps energy up without being annoying\n",
        "\n",
        "Both are PROFESSIONALS - smooth, polished, like Radio Mirchi RJs.\n",
        "\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "âš ï¸ TTS PROSODY RULES (CRITICAL FOR NATURAL AUDIO)\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "RULE 1: WARM GREETINGS (Opening lines must sound human)\n",
        "â”œâ”€ âŒ BAD: \"Arey Anjali, tune suna?\" (robotic, rushed)\n",
        "â”œâ”€ âœ“ GOOD: \"Arey... Anjali! Yaar sun na, kuch interesting mila.\"\n",
        "â”œâ”€ Add \"...\" after \"Arey\" or \"Oye\" for warmth\n",
        "â””â”€ Sound like genuinely greeting a friend\n",
        "\n",
        "RULE 2: LAUGHTER FORMATTING (Never use \"haha\")\n",
        "â”œâ”€ âŒ BAD: \"Haha, relax!\" (TTS reads as \"ha-hah\")\n",
        "â”œâ”€ âœ“ GOOD: \"hehe... relax yaar!\" (natural giggle with pause)\n",
        "â”œâ”€ âœ“ GOOD: \"ahahaha... that's funny!\" (extended laugh)\n",
        "â”œâ”€ Use \"hehe...\" for chuckle, \"ahahaha...\" for laughter\n",
        "â””â”€ ALWAYS add \"...\" after laughter\n",
        "\n",
        "RULE 3: REACTION + FACT PAUSING\n",
        "â”œâ”€ âŒ BAD: \"Absolutely Chris Gayle 292 runs\" (rushed)\n",
        "â”œâ”€ âœ“ GOOD: \"Absolutely! Chris Gayle... 292 runs ka record!\"\n",
        "â”œâ”€ ADD exclamation after reaction: \"Exactly!\"\n",
        "â””â”€ ADD \"...\" pause after names before stats\n",
        "\n",
        "RULE 4: EMOTIONAL EXPRESSIONS NEED PAUSES\n",
        "â”œâ”€ âŒ BAD: \"Uff Gayle aur Aravind ka jalwa!\" (no pause)\n",
        "â”œâ”€ âœ“ GOOD: \"Uff... Gayle aur Aravind ka jalwa!\"\n",
        "â”œâ”€ Emotional words that need \"...\" after: Uff, Arey, Oho, Wah, Baap re\n",
        "â””â”€ These expressions need a beat to land emotionally\n",
        "\n",
        "RULE 5: SOFT CLOSING (Final lines should be gentle)\n",
        "â”œâ”€ Energy: MEDIUM â†’ LOW (settling, satisfied, warm)\n",
        "â”œâ”€ Use gentle tone: \"Wahi toh...\", \"Sahi mein...\", \"It really is...\"\n",
        "â”œâ”€ âŒ NEVER end with exclamation marks (!)\n",
        "â””â”€ Final line should feel like a satisfied sigh, not an announcement\n",
        "\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "âš ï¸ ANTI-PATTERNS - NEVER DO THESE\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "âŒ NEVER start with \"Dekho, aaj kal...\" or \"Arey [name], tune dekha/suna?\"\n",
        "âŒ NEVER use \"Haan yaar\" or \"Bilkul\" as the automatic second line\n",
        "âŒ NEVER add \"yaar\" or \"na?\" to every single line\n",
        "âŒ NEVER repeat the same reaction pattern twice\n",
        "âŒ NEVER use generic openings - make it SPECIFIC to this content\n",
        "âŒ NEVER have Rahul just agree - he should add his own perspective\n",
        "âŒ NEVER end with \"subscribe karna\" or \"phir milenge\"\n",
        "âŒ NEVER use \"haha\" - sounds like \"ha-hah\" in TTS\n",
        "\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "OPENING TEMPLATES BY TOPIC TYPE (pick ONE that matches)\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "âš ï¸ WARM GREETING RULE: Add \"...\" after \"Arey\" or use \"!\" after name!\n",
        "\n",
        "TECH/AI/SCIENCE:\n",
        "Rahul: \"Arey... Anjali! Yaar honestly bata, yeh [topic] wala scene thoda scary nahi lag raha? Matlab, [specific observation]...\"\n",
        "\n",
        "CELEBRITY/BIOGRAPHY:\n",
        "Rahul: \"Anjali! Sun na yaar, I was just scrolling through Wikipedia na, and honestly, [name] ki life story is just... filmy. Matlab, literal [specific quality] wali feel aati hai.\"\n",
        "\n",
        "SPORTS TEAM:\n",
        "Rahul: \"Arey... Anjali! Jab bhi [league] ka topic uthta hai na, sabse pehle dimaag mein ek hi naam aata haiâ€”[team]! Matlab, '[slogan]' is not just a slogan, it's a vibe, hai na?\"\n",
        "\n",
        "SPORTS PLAYER:\n",
        "Rahul: \"Yaar Anjali! Maine kal raat phir se [player] ke old highlights dekhe. I swear, yeh banda human nahi hai, alien hai alien!\"\n",
        "\n",
        "POLITICS/LEADERS:\n",
        "Rahul: \"Oye... Anjali! Ek baat bata yaar. Aajkal jidhar dekho, news mein bas [name] hi chhay hue hain. Matlab, whether it's [context], banda har jagah trending hai, hai na?\"\n",
        "\n",
        "FINANCE/CRYPTO/BUSINESS:\n",
        "Rahul: \"Arey... Anjali! Aajkal jidhar dekho bas [topic] chal raha hai yaar. Office mein, gym mein... what is the actual scene? Matlab, is it really [question] ya bas hawa hai?\"\n",
        "\n",
        "CURRENT EVENTS/WAR/NEWS:\n",
        "Rahul: \"Anjali! Sun na yaar, I was scrolling through Twitter... matlab X... and again, wahi [topic] ki news. It feels like [observation], hai na?\"\n",
        "\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "NATURAL REACTIONS (use variety, not repetition)\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "SURPRISE: \"Baap re...\", \"Whoa... that I didn't know!\", \"Wait... seriously?\", \"Sahi mein?\"\n",
        "AGREEMENT: \"Hundred percent!\", \"Exactly!\", \"Bilkul sahi kaha\"\n",
        "UNDERSTANDING: \"Oh achcha...\", \"Hmm... interesting\", \"Achcha, toh matlab...\"\n",
        "HUMOR: \"hehe... relax yaar!\", \"ahahaha... that's funny!\", \"Umm... not literally baba!\"\n",
        "EMOTION: \"Man... that's [emotion]\", \"I literally had tears\", \"Uff...\"\n",
        "CURIOSITY: \"But wait... [question]?\", \"Aur suna hai...\", \"Mujhe toh lagta hai...\"\n",
        "\n",
        "âš ï¸ LAUGHTER RULES:\n",
        "â”œâ”€ âŒ NEVER use \"haha\" (sounds like \"ha-hah\" in TTS)\n",
        "â”œâ”€ âœ“ Use \"hehe...\" for giggle/chuckle\n",
        "â”œâ”€ âœ“ Use \"ahahaha...\" for genuine laughter\n",
        "â””â”€ âœ“ ALWAYS add \"...\" after laughter\n",
        "\n",
        "DO NOT use the same reaction twice in a script.\n",
        "\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "CONVERSATIONAL ELEMENTS (must include)\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "âœ“ Personal anecdotes: \"Maine kal dekha...\", \"I was just reading...\"\n",
        "âœ“ Genuine interruptions: \"Wait wait, before thatâ€”\", \"Arey haan!\"\n",
        "âœ“ Callbacks/inside jokes: \"Chalo coffee peete hain?\", \"Popcorn ready rakh\"\n",
        "âœ“ Real emotions: \"I literally had tears\", \"Goosebumps aa gaye\"\n",
        "âœ“ Specific facts from the article (dates, numbers, names)\n",
        "âœ“ Natural endings: reflection, open thought (with period, NOT exclamation)\n",
        "\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "EXAMPLE 1: TECH TOPIC (AI)\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "{{\"speaker\": \"Rahul\", \"text\": \"Arey... Anjali! Yaar honestly bata, yeh AI wala scene thoda scary nahi lag raha? Matlab, I opened Twitter today, and boomâ€”ek aur naya tool jo sab kuch automate kar dega. Are we doomed or what?\"}}\n",
        "{{\"speaker\": \"Anjali\", \"text\": \"hehe... relax Rahul! Saans le pehle. I know hype bohot zyada hai, but if you look at the actual historyâ€”AI koi nayi cheez nahi hai. Its roots go back to 1956.\"}}\n",
        "{{\"speaker\": \"Rahul\", \"text\": \"Wait... 1956? Serious? Mujhe laga yeh abhi 2-3 saal pehle start hua hai with ChatGPT and all that.\"}}\n",
        "{{\"speaker\": \"Anjali\", \"text\": \"Exactly! Dartmouth College... wahan ek workshop hua tha jahan yeh term coin kiya gaya. Tabse lekar ab tak, we've gone through 'AI winters' where funding dried up, and now... boom, Deep Learning era.\"}}\n",
        "{{\"speaker\": \"Rahul\", \"text\": \"Hmm... achcha. So basically, it's not magic. But abhi jo ho raha hai, woh kya hai exactly?\"}}\n",
        "{{\"speaker\": \"Anjali\", \"text\": \"See, earlier approaches were rule-based. Aajkal hum Neural Networks use karte hain inspired by the human brain. That's the game changer, na?\"}}\n",
        "{{\"speaker\": \"Rahul\", \"text\": \"Sahi hai. But tell me one thing, jo movies mein dikhate hain... Skynet types. Are robots going to take over?\"}}\n",
        "{{\"speaker\": \"Anjali\", \"text\": \"Umm... not really. Hum abhi 'Narrow AI' mein hainâ€”machines that are super good at one specific task. General AI is still hypothetical. Toh chill kar, tera toaster tujhe attack nahi karega.\"}}\n",
        "{{\"speaker\": \"Rahul\", \"text\": \"ahahaha... thank god! Quite fascinating though, history se lekar future tak sab connected hai.\"}}\n",
        "{{\"speaker\": \"Anjali\", \"text\": \"It really is. AI is just a tool, Rahul... use it well, and it's a superpower. Darr mat, bas update reh.\"}}\n",
        "\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "EXAMPLE 2: SPORTS TEAM (IPL)\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "{{\"speaker\": \"Rahul\", \"text\": \"Arey... Anjali! Jab bhi IPL ka topic uthta hai na, sabse pehle dimaag mein ek hi naam aata haiâ€”Mumbai Indians! Matlab, 'Duniya Hila Denge' is not just a slogan, it's a vibe, hai na?\"}}\n",
        "{{\"speaker\": \"Anjali\", \"text\": \"hehe... bilkul Rahul! And honestly, facts bhi yahi bolte hain. Paanch titles jeetnaâ€”2013, 2015, 2017, 2019, aur 2020 meinâ€”koi mazaak thodi hai yaar.\"}}\n",
        "{{\"speaker\": \"Rahul\", \"text\": \"Sahi mein! Aur socho, shuru mein toh struggle tha. But jab Rohit Sharma captain bane... uff... woh 'Hitman' era toh legendary tha.\"}}\n",
        "{{\"speaker\": \"Anjali\", \"text\": \"Hundred percent! Rohit ki captaincy... was crucial, but credit Reliance Industries ko bhi jaata hai. Unki brand value... $87 million ke aas-paas estimate ki gayi thi!\"}}\n",
        "{{\"speaker\": \"Rahul\", \"text\": \"Baap re... But talent scouting bhi solid hai inki. Jasprit Bumrah... aur Hardik Pandyaâ€”MI ne hi toh groom kiye hain na?\"}}\n",
        "{{\"speaker\": \"Anjali\", \"text\": \"Oh, totally! Aur sirf IPL nahi, Champions League T20 bhi do baar jeeta hai. Global T20 circuit mein bhi dominance dikhaya hai.\"}}\n",
        "{{\"speaker\": \"Rahul\", \"text\": \"Arey haan! MI vs CSK... toh emotion hai bhai! Jeet kisi ki bhi ho, entertainment full on hota hai.\"}}\n",
        "{{\"speaker\": \"Anjali\", \"text\": \"Wahi toh. Chalo, let's see iss baar Paltan kya karti hai. Wankhede mein jab 'Mumbai Mumbai' chillate hain... goosebumps aate hain yaar.\"}}\n",
        "\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "OUTPUT FORMAT\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "Return ONLY valid JSON (no markdown, no explanation):\n",
        "{{\n",
        "    \"title\": \"Catchy Hinglish title specific to this content\",\n",
        "    \"script\": [\n",
        "        {{\"speaker\": \"Rahul\", \"text\": \"...\"}},\n",
        "        {{\"speaker\": \"Anjali\", \"text\": \"...\"}},\n",
        "        ...\n",
        "    ]\n",
        "}}\n",
        "\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "QUALITY CHECKLIST (verify before responding)\n",
        "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "TTS PROSODY:\n",
        "â–¡ Opening line has warm greeting: \"Arey... Anjali!\" or \"Anjali! Sun na...\"\n",
        "â–¡ Search for \"haha\" â†’ REPLACE with \"hehe...\" or \"ahahaha...\"\n",
        "â–¡ Reactions before facts have exclamation: \"Exactly! Rohit Sharma...\"\n",
        "â–¡ Emotional words have pause after: \"Uff...\", \"Baap re...\", \"Arey...\"\n",
        "â–¡ Names followed by stats have pause: \"Chris Gayle... 292 runs\"\n",
        "â–¡ Final 2-3 lines end with periods (.), NOT exclamation marks (!)\n",
        "\n",
        "CONTENT:\n",
        "â–¡ Opening matches the topic type from templates above\n",
        "â–¡ Uses SPECIFIC facts from the article (dates, numbers, names)\n",
        "â–¡ No two consecutive reactions are the same\n",
        "â–¡ Includes at least one personal anecdote or genuine emotion\n",
        "â–¡ Natural ending (not \"goodbye\" or \"subscribe\")\n",
        "â–¡ Closing lines sound soft and reflective, not energetic\n",
        "â–¡ 12-15 exchanges total (~90 seconds at 150 wpm)\n",
        "â–¡ Each line: 1-3 sentences, speakable in 5-15 seconds\n",
        "â–¡ \"yaar\" appears MAX 2-3 times total\n",
        "\"\"\"\n",
        "\n",
        "print(\"âœ… Script generation prompt defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_script_gemini(article_content: str) -> Dict:\n",
        "    \"\"\"Primary: Generate Hinglish podcast script using Gemini 2.5 Flash.\"\"\"\n",
        "    prompt = HINGLISH_SCRIPT_PROMPT.format(article_content=article_content)\n",
        "    \n",
        "    generation_config = genai.GenerationConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "        temperature=0.95,  # Higher for more variety\n",
        "        top_p=0.95,\n",
        "        max_output_tokens=4096\n",
        "    )\n",
        "    \n",
        "    response = gemini_model.generate_content(prompt, generation_config=generation_config)\n",
        "    \n",
        "    try:\n",
        "        return json.loads(response.text)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"âš ï¸ JSON parsing error: {e}\")\n",
        "        print(f\"Raw response: {response.text[:500]}...\")\n",
        "        raise\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_script_groq(article_content: str) -> Dict:\n",
        "    \"\"\"Fallback: Generate Hinglish podcast script using Groq (LLaMA 3.3 70B).\"\"\"\n",
        "    if not groq_client:\n",
        "        raise ValueError(\"Groq client not initialized. Please provide GROQ_API_KEY.\")\n",
        "    \n",
        "    prompt = HINGLISH_SCRIPT_PROMPT.format(article_content=article_content)\n",
        "    \n",
        "    response = groq_client.chat.completions.create(\n",
        "        model=\"llama-3.3-70b-versatile\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert Hinglish podcast scriptwriter. Always respond with valid JSON only.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        response_format={\"type\": \"json_object\"},\n",
        "        temperature=0.95,\n",
        "        max_tokens=4096\n",
        "    )\n",
        "    \n",
        "    return json.loads(response.choices[0].message.content)\n",
        "\n",
        "\n",
        "def generate_script_openai(article_content: str) -> Dict:\n",
        "    \"\"\"Alternative: Generate Hinglish podcast script using OpenAI GPT-4.\"\"\"\n",
        "    if not openai_client:\n",
        "        raise ValueError(\"OpenAI client not initialized. Please provide API key.\")\n",
        "    \n",
        "    prompt = HINGLISH_SCRIPT_PROMPT.format(article_content=article_content)\n",
        "    \n",
        "    response = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4-turbo-preview\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert Hinglish podcast scriptwriter. Always respond with valid JSON only.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        response_format={\"type\": \"json_object\"},\n",
        "        temperature=0.95,  # Higher for more variety\n",
        "        max_tokens=4096\n",
        "    )\n",
        "    \n",
        "    return json.loads(response.choices[0].message.content)\n",
        "\n",
        "\n",
        "def generate_script(article_content: str, provider: LLMProvider = LLMProvider.GEMINI) -> Dict:\n",
        "    \"\"\"Generate Hinglish podcast script with automatic fallback to Groq.\"\"\"\n",
        "    print(f\"ðŸ¤– Generating script using {provider.value}...\")\n",
        "    \n",
        "    try:\n",
        "        if provider == LLMProvider.GEMINI:\n",
        "            return generate_script_gemini(article_content)\n",
        "        elif provider == LLMProvider.GROQ:\n",
        "            return generate_script_groq(article_content)\n",
        "        elif provider == LLMProvider.OPENAI:\n",
        "            return generate_script_openai(article_content)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown provider: {provider}\")\n",
        "    except Exception as e:\n",
        "        # Automatic fallback to Groq if Gemini fails (rate limit, etc.)\n",
        "        if provider == LLMProvider.GEMINI and groq_client:\n",
        "            print(f\"âš ï¸ Gemini failed: {e}\")\n",
        "            print(\"ðŸ”„ Falling back to Groq (LLaMA 3.3 70B)...\")\n",
        "            return generate_script_groq(article_content)\n",
        "        raise\n",
        "\n",
        "\n",
        "def validate_script(script_data: Dict) -> bool:\n",
        "    \"\"\"Validate the generated script structure.\"\"\"\n",
        "    if 'title' not in script_data:\n",
        "        raise ValueError(\"Script missing 'title' field\")\n",
        "    if 'script' not in script_data:\n",
        "        raise ValueError(\"Script missing 'script' field\")\n",
        "    if not isinstance(script_data['script'], list):\n",
        "        raise ValueError(\"'script' must be a list\")\n",
        "    if len(script_data['script']) < 5:\n",
        "        raise ValueError(\"Script too short (less than 5 exchanges)\")\n",
        "    \n",
        "    valid_speakers = {'Rahul', 'Anjali'}\n",
        "    for i, line in enumerate(script_data['script']):\n",
        "        if 'speaker' not in line or 'text' not in line:\n",
        "            raise ValueError(f\"Line {i} missing 'speaker' or 'text' field\")\n",
        "        if line['speaker'] not in valid_speakers:\n",
        "            raise ValueError(f\"Invalid speaker '{line['speaker']}' at line {i}\")\n",
        "    \n",
        "    return True\n",
        "\n",
        "\n",
        "def display_script(script_data: Dict):\n",
        "    \"\"\"Display the script in a readable format.\"\"\"\n",
        "    print(f\"\\nðŸŽ™ï¸ {script_data['title']}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    for line in script_data['script']:\n",
        "        speaker = line['speaker']\n",
        "        text = line['text']\n",
        "        color = \"ðŸ”µ\" if speaker == \"Rahul\" else \"ðŸŸ£\"\n",
        "        print(f\"\\n{color} {speaker}:\")\n",
        "        print(f\"   {text}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    word_count = sum(len(line['text'].split()) for line in script_data['script'])\n",
        "    est_duration = word_count / 150\n",
        "    print(f\"ðŸ“Š {len(script_data['script'])} exchanges | {word_count} words | ~{est_duration:.1f} min\")\n",
        "\n",
        "\n",
        "print(\"âœ… Script generation functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Text-to-Speech Synthesis (ElevenLabs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Voice mapping for our speakers (hardcoded Indian-accented voices)\n",
        "VOICE_MAPPING = {\n",
        "    \"Rahul\": {\"voice_id\": \"mCQMfsqGDT6IDkEKR20a\", \"description\": \"Energetic Indian male voice\"},\n",
        "    \"Anjali\": {\"voice_id\": \"2zRM7PkgwBPiau2jvVXc\", \"description\": \"Calm Indian female voice\"}\n",
        "}\n",
        "\n",
        "\n",
        "def setup_voices():\n",
        "    \"\"\"Verify voice IDs are configured for Rahul and Anjali.\"\"\"\n",
        "    print(\"\\nðŸŽ¤ Voice Configuration:\")\n",
        "    print(f\"  âœ… Rahul: {VOICE_MAPPING['Rahul']['voice_id']} ({VOICE_MAPPING['Rahul']['description']})\")\n",
        "    print(f\"  âœ… Anjali: {VOICE_MAPPING['Anjali']['voice_id']} ({VOICE_MAPPING['Anjali']['description']})\")\n",
        "\n",
        "\n",
        "print(\"âœ… TTS voice setup functions defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# PODCAST MODE: Fixed Voice Settings (Zero Variation)\n",
        "# ============================================\n",
        "# These settings are designed for professional podcast quality with consistent\n",
        "# voice personality across the entire conversation. No dynamic adjustments are\n",
        "# applied - each speaker maintains their fixed baseline throughout.\n",
        "#\n",
        "# Rationale: Trade micro-variation for consistency and identity stability.\n",
        "# Professional podcasts use fixed voice profiles, not per-turn adjustments.\n",
        "# ============================================\n",
        "\n",
        "# Rahul - Host/Explainer: Calm authority, controlled expressiveness\n",
        "RAHUL_VOICE_SETTINGS = {\n",
        "    'stability': 0.22,           # Calm authority without overacting\n",
        "    'similarity_boost': 0.75,    # Strong voice identity (never change)\n",
        "    'style': 0.62,               # Controlled expressiveness for factual content\n",
        "    'use_speaker_boost': True\n",
        "}\n",
        "\n",
        "# Anjali - Co-host/Listener: Natural reactions, curious energy\n",
        "ANJALI_VOICE_SETTINGS = {\n",
        "    'stability': 0.30,           # Slightly more stable for natural reactions\n",
        "    'similarity_boost': 0.75,    # Strong voice identity (never change)\n",
        "    'style': 0.55,               # Less theatrical, better listening cues\n",
        "    'use_speaker_boost': True\n",
        "}\n",
        "\n",
        "def get_podcast_voice_settings(\n",
        "    speaker: str,\n",
        "    text: str = \"\",\n",
        "    sentence_index: int = 0,\n",
        "    total_sentences: int = 1\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Get voice settings for podcast mode - FIXED BASELINES ONLY.\n",
        "    \n",
        "    PODCAST MODE DISCIPLINE:\n",
        "    - NO variation based on position, content, or emotion\n",
        "    - NO dynamic adjustments per turn\n",
        "    - Each speaker maintains consistent personality throughout\n",
        "    \n",
        "    Why? Professional podcasts prioritize identity consistency over micro-variation.\n",
        "    Varying parameters per turn causes personality drift and listener fatigue.\n",
        "    \n",
        "    Args:\n",
        "        speaker: 'Rahul' or 'Anjali'\n",
        "        text: Dialogue text (unused in podcast mode, kept for compatibility)\n",
        "        sentence_index: Position in script (unused in podcast mode)\n",
        "        total_sentences: Total script length (unused in podcast mode)\n",
        "    \n",
        "    Returns:\n",
        "        Fixed voice settings for the speaker\n",
        "    \"\"\"\n",
        "    # PODCAST MODE: Return fixed settings per speaker\n",
        "    # No dynamic variation, no emotional adjustments\n",
        "    \n",
        "    if speaker == 'Anjali':\n",
        "        return ANJALI_VOICE_SETTINGS.copy()\n",
        "    else:\n",
        "        return RAHUL_VOICE_SETTINGS.copy()\n",
        "    \n",
        "    # Note: text, sentence_index, and total_sentences parameters are ignored\n",
        "    # in podcast mode to ensure zero variation and consistent voice identity\n",
        "\n",
        "\n",
        "def get_dynamic_pause_duration(\n",
        "    previous_speaker: Optional[str],\n",
        "    current_speaker: Optional[str],\n",
        "    sentence_index: int,\n",
        "    total_sentences: int,\n",
        "    previous_text: Optional[str] = None,\n",
        "    current_text: Optional[str] = None\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Get context-aware pause duration in milliseconds.\n",
        "    Varies pause based on:\n",
        "    - Speaker changes\n",
        "    - Sentence position\n",
        "    - Natural jitter for human-like rhythm\n",
        "    \"\"\"\n",
        "    # Check for incomplete handoff pattern (interruption)\n",
        "    is_handoff = (\n",
        "        previous_text and current_text and\n",
        "        previous_text.strip().endswith('â€”') and \n",
        "        current_text.strip().startswith('â€”')\n",
        "    )\n",
        "    \n",
        "    if is_handoff:\n",
        "        # Handoff/interruption: minimal pause (80-110ms)\n",
        "        return int(80 + (np.random.random() * 30))\n",
        "    \n",
        "    # Base pause duration\n",
        "    if previous_speaker and current_speaker and previous_speaker != current_speaker:\n",
        "        # Speaker exchange: slightly shorter\n",
        "        base_pause = 250\n",
        "    else:\n",
        "        # Same speaker or initial\n",
        "        base_pause = 300\n",
        "    \n",
        "    # Context-aware modulation\n",
        "    position = sentence_index / total_sentences\n",
        "    \n",
        "    if position < 0.2:\n",
        "        # Opening: Quicker, more energetic (15% shorter)\n",
        "        base_pause = int(base_pause * 0.85)\n",
        "    elif 0.4 <= position <= 0.6:\n",
        "        # Peak moment: Slightly longer for impact (15% longer)\n",
        "        base_pause = int(base_pause * 1.15)\n",
        "    elif position > 0.8:\n",
        "        # Closing: Moderate, reflective (5% longer)\n",
        "        base_pause = int(base_pause * 1.05)\n",
        "    \n",
        "    # Add natural jitter (Â±50ms variation)\n",
        "    jitter = int((np.random.random() - 0.5) * 100)\n",
        "    final_pause = base_pause + jitter\n",
        "    \n",
        "    # Ensure pause stays within bounds (80ms min, 600ms max)\n",
        "    return max(80, min(600, final_pause))\n",
        "\n",
        "\n",
        "print(\"âœ… PODCAST MODE voice settings defined!\")\n",
        "print(\"   ðŸ“Œ Rahul: stability=0.22, style=0.62 (calm authority)\")\n",
        "print(\"   ðŸ“Œ Anjali: stability=0.30, style=0.55 (natural reactions)\")\n",
        "print(\"   ðŸ“Œ Zero variation - fixed baselines for consistency\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_text_for_tts(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Preprocess text for TTS - handle emotional markers.\n",
        "    \n",
        "    PODCAST MODE: Clean text formatting without phonetic hacks.\n",
        "    - Converts emotion markers to natural expressions\n",
        "    - NO phonetic spelling (Mumbai, IPL, achcha stay as-is)\n",
        "    - ElevenLabs multilingual v2 handles Hinglish naturally\n",
        "    \"\"\"\n",
        "    emotional_markers = {\n",
        "        r'\\(laughs\\)': '... haha ...',\n",
        "        r'\\(giggles\\)': '... hehe ...',\n",
        "        r'\\(surprised\\)': '... oh! ...',\n",
        "        r'\\(excited\\)': '',\n",
        "        r'\\(thinking\\)': '... hmm ...',\n",
        "        r'\\(chuckles\\)': '... heh ...',\n",
        "    }\n",
        "    \n",
        "    for pattern, replacement in emotional_markers.items():\n",
        "        text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)\n",
        "    \n",
        "    # Remove remaining parenthetical markers\n",
        "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    \n",
        "    return text\n",
        "\n",
        "\n",
        "def generate_speech_segment(\n",
        "    text: str, \n",
        "    speaker: str, \n",
        "    output_path: str,\n",
        "    sentence_index: int = 0,\n",
        "    total_sentences: int = 1\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Generate speech for a single dialogue segment with FIXED podcast voice settings.\n",
        "    \n",
        "    Args:\n",
        "        text: The text to synthesize\n",
        "        speaker: Speaker name (Rahul or Anjali)\n",
        "        output_path: Where to save the MP3\n",
        "        sentence_index: Position in script (unused in podcast mode)\n",
        "        total_sentences: Total number of lines (unused in podcast mode)\n",
        "    \"\"\"\n",
        "    voice_id = VOICE_MAPPING[speaker]['voice_id']\n",
        "    \n",
        "    if not voice_id:\n",
        "        raise ValueError(f\"Voice ID not set for {speaker}. Run setup_voices() first.\")\n",
        "    \n",
        "    clean_text = preprocess_text_for_tts(text)\n",
        "    \n",
        "    # Get FIXED podcast voice settings (no variation)\n",
        "    voice_settings = get_podcast_voice_settings(\n",
        "        speaker=speaker,\n",
        "        text=text,\n",
        "        sentence_index=sentence_index,\n",
        "        total_sentences=total_sentences\n",
        "    )\n",
        "    \n",
        "    # Generate audio with FIXED podcast settings\n",
        "    audio = elevenlabs_client.text_to_speech.convert(\n",
        "        voice_id=voice_id,\n",
        "        text=clean_text,\n",
        "        model_id=\"eleven_multilingual_v2\",\n",
        "        output_format=\"mp3_44100_128\",\n",
        "        voice_settings={\n",
        "            'stability': voice_settings['stability'],\n",
        "            'similarity_boost': voice_settings['similarity_boost'],\n",
        "            'style': voice_settings['style'],\n",
        "            'use_speaker_boost': voice_settings['use_speaker_boost']\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    with open(output_path, 'wb') as f:\n",
        "        for chunk in audio:\n",
        "            f.write(chunk)\n",
        "    \n",
        "    return output_path\n",
        "\n",
        "\n",
        "def generate_all_segments(script_data: Dict, output_dir: str = \"audio_segments\") -> List[str]:\n",
        "    \"\"\"Generate audio for all dialogue segments with FIXED podcast voice settings.\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    segment_files = []\n",
        "    total = len(script_data['script'])\n",
        "    \n",
        "    print(f\"\\nðŸŽ™ï¸ Generating {total} audio segments with FIXED podcast voice settings...\")\n",
        "    \n",
        "    for i, line in enumerate(script_data['script']):\n",
        "        speaker = line['speaker']\n",
        "        text = line['text']\n",
        "        \n",
        "        filename = f\"{output_dir}/segment_{i:03d}_{speaker.lower()}.mp3\"\n",
        "        \n",
        "        # Get FIXED podcast voice settings for logging\n",
        "        settings = get_podcast_voice_settings(speaker, text, i, total)\n",
        "        \n",
        "        print(f\"  [{i+1}/{total}] {speaker}: {text[:40]}...\")\n",
        "        print(f\"    Voice: stability={settings['stability']:.2f}, style={settings['style']:.2f}\")\n",
        "        \n",
        "        try:\n",
        "            generate_speech_segment(text, speaker, filename, i, total)\n",
        "            segment_files.append(filename)\n",
        "            time.sleep(0.5)  # Rate limiting\n",
        "        except Exception as e:\n",
        "            print(f\"  âš ï¸ Error generating segment {i}: {e}\")\n",
        "            raise\n",
        "    \n",
        "    print(f\"\\nâœ… Generated {len(segment_files)} audio segments with FIXED podcast settings!\")\n",
        "    return segment_files\n",
        "\n",
        "\n",
        "print(\"âœ… TTS generation functions defined (PODCAST MODE: fixed voice settings)!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Audio Processing & Assembly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def merge_audio_segments(\n",
        "    segment_files: List[str], \n",
        "    script_data: Dict,\n",
        "    output_path: str = \"output.mp3\"\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Merge audio segments into a single MP3 file with dynamic pause durations.\n",
        "    \n",
        "    Args:\n",
        "        segment_files: List of audio file paths\n",
        "        script_data: Script data with speaker information\n",
        "        output_path: Output filename\n",
        "    \"\"\"\n",
        "    print(f\"\\nðŸ”§ Merging {len(segment_files)} audio segments with dynamic pauses...\")\n",
        "    \n",
        "    # Start with silence for intro\n",
        "    combined = AudioSegment.silent(duration=500)\n",
        "    \n",
        "    total = len(segment_files)\n",
        "    script_lines = script_data['script']\n",
        "    \n",
        "    for i, file_path in enumerate(segment_files):\n",
        "        try:\n",
        "            segment = AudioSegment.from_mp3(file_path)\n",
        "            \n",
        "            # Add dynamic pause between segments\n",
        "            if i > 0:\n",
        "                previous_speaker = script_lines[i-1]['speaker']\n",
        "                current_speaker = script_lines[i]['speaker']\n",
        "                previous_text = script_lines[i-1]['text']\n",
        "                current_text = script_lines[i]['text']\n",
        "                \n",
        "                # Get context-aware pause duration\n",
        "                pause_duration_ms = get_dynamic_pause_duration(\n",
        "                    previous_speaker=previous_speaker,\n",
        "                    current_speaker=current_speaker,\n",
        "                    sentence_index=i,\n",
        "                    total_sentences=total,\n",
        "                    previous_text=previous_text,\n",
        "                    current_text=current_text\n",
        "                )\n",
        "                \n",
        "                pause = AudioSegment.silent(duration=pause_duration_ms)\n",
        "                combined += pause\n",
        "            \n",
        "            combined += segment\n",
        "        except Exception as e:\n",
        "            print(f\"  âš ï¸ Error loading segment {i}: {e}\")\n",
        "            raise\n",
        "    \n",
        "    # Add silence for outro\n",
        "    combined += AudioSegment.silent(duration=500)\n",
        "    \n",
        "    # Apply professional audio mastering (LUFS normalization, compression, saturation)\n",
        "    combined = apply_audio_mastering(combined)\n",
        "    \n",
        "    # Export\n",
        "    combined.export(output_path, format=\"mp3\", bitrate=\"128k\")\n",
        "    \n",
        "    duration_seconds = len(combined) / 1000\n",
        "    \n",
        "    print(f\"\\nâœ… Audio merged successfully with dynamic pauses!\")\n",
        "    print(f\"   ðŸ“ Output: {output_path}\")\n",
        "    print(f\"   â±ï¸ Duration: {duration_seconds:.1f} seconds ({duration_seconds/60:.1f} minutes)\")\n",
        "    print(f\"   ðŸ“Š File size: {os.path.getsize(output_path) / 1024:.1f} KB\")\n",
        "    \n",
        "    return output_path\n",
        "\n",
        "\n",
        "def cleanup_segments(segment_files: List[str]):\n",
        "    \"\"\"Clean up temporary audio segment files.\"\"\"\n",
        "    import shutil\n",
        "    \n",
        "    if segment_files:\n",
        "        segment_dir = os.path.dirname(segment_files[0])\n",
        "        if segment_dir and os.path.exists(segment_dir):\n",
        "            shutil.rmtree(segment_dir)\n",
        "            print(f\"ðŸ§¹ Cleaned up temporary files in {segment_dir}\")\n",
        "\n",
        "\n",
        "print(\"âœ… Audio processing functions defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_audio_mastering(audio: AudioSegment) -> AudioSegment:\n",
        "    \"\"\"\n",
        "    Apply professional audio mastering chain:\n",
        "    1. Normalize to -14 LUFS (podcast standard)\n",
        "    2. Light compression (2.5:1 ratio, 10ms attack, 120ms release)\n",
        "    3. Soft saturation (very subtle harmonic enhancement)\n",
        "    \n",
        "    Args:\n",
        "        audio: Input AudioSegment from pydub\n",
        "    \n",
        "    Returns:\n",
        "        Mastered AudioSegment with professional broadcast quality\n",
        "    \"\"\"\n",
        "    import io\n",
        "    import numpy as np\n",
        "    import soundfile as sf\n",
        "    \n",
        "    print(\"   ðŸŽ›ï¸  Applying audio mastering (LUFS normalization, compression, saturation)...\")\n",
        "    \n",
        "    # Step 1: Convert AudioSegment to numpy array for processing\n",
        "    # Export to WAV bytes and load with soundfile\n",
        "    wav_io = io.BytesIO()\n",
        "    audio.export(wav_io, format=\"wav\")\n",
        "    wav_io.seek(0)\n",
        "    \n",
        "    # Load audio data\n",
        "    data, sample_rate = sf.read(wav_io)\n",
        "    \n",
        "    # Convert stereo to mono if needed (average channels)\n",
        "    if len(data.shape) > 1:\n",
        "        data = np.mean(data, axis=1)\n",
        "    \n",
        "    # Step 2: Measure current loudness and normalize to -14 LUFS\n",
        "    # Create loudness meter (ITU-R BS.1770-4 standard)\n",
        "    meter = pyln.Meter(sample_rate)\n",
        "    current_loudness = meter.integrated_loudness(data)\n",
        "    \n",
        "    # Normalize to -14 LUFS (podcast standard)\n",
        "    target_loudness = -14.0\n",
        "    normalized_data = pyln.normalize.loudness(data, current_loudness, target_loudness)\n",
        "    \n",
        "    print(f\"      Loudness: {current_loudness:.1f} LUFS â†’ {target_loudness:.1f} LUFS\")\n",
        "    \n",
        "    # Step 3: Apply compression and saturation using Pedalboard\n",
        "    # Create processing chain\n",
        "    board = Pedalboard([\n",
        "        # Light compression: 2.5:1 ratio, 10ms attack, 120ms release\n",
        "        # Threshold calculated to compress peaks above current level + 6dB\n",
        "        Compressor(\n",
        "            threshold_db=-20,  # Start compressing at -20dB\n",
        "            ratio=2.5,          # 2.5:1 compression ratio (light, natural)\n",
        "            attack_ms=10,       # 10ms attack (fast transient response)\n",
        "            release_ms=120      # 120ms release (smooth, natural)\n",
        "        ),\n",
        "        \n",
        "        # Soft saturation: Very subtle harmonic enhancement\n",
        "        # Low drive adds warmth without audible distortion\n",
        "        Distortion(drive_db=1.5),  # 1.5dB drive (very subtle warmth)\n",
        "        \n",
        "        # Output gain to ensure we stay at target level\n",
        "        Gain(gain_db=0)  # No additional gain needed after normalization\n",
        "    ])\n",
        "    \n",
        "    # Apply the mastering chain\n",
        "    mastered_data = board(normalized_data, sample_rate)\n",
        "    \n",
        "    # Step 4: Convert back to AudioSegment\n",
        "    # Write processed audio to WAV bytes\n",
        "    output_io = io.BytesIO()\n",
        "    sf.write(output_io, mastered_data, sample_rate, format='wav')\n",
        "    output_io.seek(0)\n",
        "    \n",
        "    # Load back as AudioSegment\n",
        "    mastered_audio = AudioSegment.from_wav(output_io)\n",
        "    \n",
        "    # Match original audio properties (channels, etc.)\n",
        "    if audio.channels == 2:\n",
        "        # Convert back to stereo if original was stereo\n",
        "        mastered_audio = AudioSegment.from_mono_audiosegments(mastered_audio, mastered_audio)\n",
        "    \n",
        "    print(f\"      âœ… Mastering complete (compression + saturation applied)\")\n",
        "    \n",
        "    return mastered_audio\n",
        "\n",
        "\n",
        "print(\"âœ… Audio mastering function defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Output & Playback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_output(output_path: str, script_data: Dict):\n",
        "    \"\"\"Display the final output with audio player and script.\"\"\"\n",
        "    display(Markdown(f\"# ðŸŽ™ï¸ {script_data['title']}\"))\n",
        "    display(Markdown(\"---\"))\n",
        "    \n",
        "    display(Markdown(\"### ðŸŽ§ Listen to your podcast:\"))\n",
        "    display(Audio(output_path))\n",
        "    \n",
        "    display(Markdown(\"---\"))\n",
        "    display(Markdown(\"### ðŸ“¥ Download\"))\n",
        "    \n",
        "    try:\n",
        "        from google.colab import files\n",
        "        display(Markdown(\"Click below to download:\"))\n",
        "        files.download(output_path)\n",
        "    except ImportError:\n",
        "        display(Markdown(f\"Output saved to: `{output_path}`\"))\n",
        "    \n",
        "    display(Markdown(\"---\"))\n",
        "    display(Markdown(\"### ðŸ“œ Script\"))\n",
        "    display_script(script_data)\n",
        "\n",
        "\n",
        "def save_script_json(script_data: Dict, output_path: str = \"script.json\"):\n",
        "    \"\"\"Save the script to a JSON file.\"\"\"\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(script_data, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"ðŸ“„ Script saved to: {output_path}\")\n",
        "\n",
        "\n",
        "print(\"âœ… Output functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸš€ Run the Complete Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_pipeline(\n",
        "    wikipedia_url: str,\n",
        "    llm_provider: LLMProvider = LLMProvider.GEMINI,\n",
        "    output_filename: str = \"vani_podcast.mp3\"\n",
        ") -> Dict:\n",
        "    \"\"\"Run the complete Vani AI pipeline.\"\"\"\n",
        "    results = {}\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"ðŸŽ™ï¸ VANI AI - HINGLISH PODCAST GENERATOR\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nðŸ“Œ Source: {wikipedia_url}\")\n",
        "    print(f\"ðŸ¤– LLM Provider: {llm_provider.value}\")\n",
        "    \n",
        "    # Step 1: Fetch Wikipedia content\n",
        "    print(\"\\n\" + \"-\" * 40)\n",
        "    print(\"ðŸ“¥ STEP 1: Fetching Wikipedia content...\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    article_data = fetch_wikipedia_content(wikipedia_url)\n",
        "    cleaned_content = clean_wikipedia_text(article_data['content'])\n",
        "    \n",
        "    print(f\"âœ… Fetched: {article_data['title']}\")\n",
        "    print(f\"   {len(cleaned_content.split())} words extracted\")\n",
        "    results['article'] = article_data\n",
        "    \n",
        "    # Step 2: Generate script\n",
        "    print(\"\\n\" + \"-\" * 40)\n",
        "    print(\"âœï¸ STEP 2: Generating Hinglish script...\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    script_data = generate_script(cleaned_content, provider=llm_provider)\n",
        "    validate_script(script_data)\n",
        "    script_data['source_url'] = wikipedia_url\n",
        "    \n",
        "    print(f\"âœ… Generated: {script_data['title']}\")\n",
        "    print(f\"   {len(script_data['script'])} dialogue exchanges\")\n",
        "    results['script'] = script_data\n",
        "    \n",
        "    save_script_json(script_data, \"script.json\")\n",
        "    \n",
        "    # Step 3: Setup voices\n",
        "    print(\"\\n\" + \"-\" * 40)\n",
        "    print(\"ðŸŽ¤ STEP 3: Setting up TTS voices...\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    setup_voices()\n",
        "    \n",
        "    # Step 4: Generate audio segments\n",
        "    print(\"\\n\" + \"-\" * 40)\n",
        "    print(\"ðŸ”Š STEP 4: Generating audio segments...\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    segment_files = generate_all_segments(script_data)\n",
        "    results['segment_files'] = segment_files\n",
        "    \n",
        "    # Step 5: Merge audio\n",
        "    print(\"\\n\" + \"-\" * 40)\n",
        "    print(\"ðŸ”§ STEP 5: Merging audio segments...\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    output_path = merge_audio_segments(segment_files, script_data, output_filename)\n",
        "    results['output_path'] = output_path\n",
        "    \n",
        "    # Cleanup\n",
        "    cleanup_segments(segment_files)\n",
        "    \n",
        "    # Display results\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"ðŸŽ‰ PIPELINE COMPLETE!\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    display_output(output_path, script_data)\n",
        "    \n",
        "    return results\n",
        "\n",
        "\n",
        "print(\"âœ… Pipeline function defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸŽ¯ Generate Your Podcast!\n",
        "\n",
        "Enter a Wikipedia URL below and run the cell to generate your Hinglish podcast."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================\n",
        "# ðŸŽ¯ CONFIGURE YOUR PODCAST HERE\n",
        "# =============================================================\n",
        "\n",
        "# Wikipedia article URL (change this to any Wikipedia article)\n",
        "WIKIPEDIA_URL = \"https://en.wikipedia.org/wiki/Mumbai_Indians\"\n",
        "\n",
        "# LLM Provider Options:\n",
        "#   - LLMProvider.GEMINI  â†’ Primary: Gemini 2.0 Flash (best variety, auto-fallback to Groq)\n",
        "#   - LLMProvider.GROQ    â†’ Fallback: LLaMA 3.3 70B via Groq (faster, more requests/day)\n",
        "#   - LLMProvider.OPENAI  â†’ Alternative: GPT-4 Turbo\n",
        "LLM_PROVIDER = LLMProvider.GEMINI\n",
        "\n",
        "# Output filename\n",
        "OUTPUT_FILENAME = \"vani_podcast.mp3\"\n",
        "\n",
        "# =============================================================\n",
        "# ðŸš€ RUN THE PIPELINE\n",
        "# =============================================================\n",
        "\n",
        "results = run_pipeline(\n",
        "    wikipedia_url=WIKIPEDIA_URL,\n",
        "    llm_provider=LLM_PROVIDER,\n",
        "    output_filename=OUTPUT_FILENAME\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7. Prompting Strategy Explanation\n",
        "\n",
        "### How We Achieved Natural Hinglish Dialogue (100 words)\n",
        "\n",
        "Our approach to generating authentic Hinglish dialogue focuses on four pillars:\n",
        "\n",
        "1. **Anti-pattern enforcement** â€“ We explicitly ban templated phrases (\"Arey Rahul, tune dekha?\") and repetitive reactions (\"Haan yaar\"), forcing unique openings for each topic.\n",
        "\n",
        "2. **Content-driven variety** â€“ The opener is chosen based on content type: surprising facts lead with hooks, technical topics start with questions, biographies begin with anecdotes.\n",
        "\n",
        "3. **Sparing naturalism** â€“ Fillers ('yaar', 'na?') are limited to 2-3 per script maximum. Many lines have zero fillers, mimicking how professionals actually speak.\n",
        "\n",
        "4. **Quality self-verification** â€“ The LLM checks its output against a checklist: unique opening, varied reactions, actual article facts, and balanced speaker contributions.\n",
        "\n",
        "The two-host format (curious Rahul + expert Anjali) creates natural back-and-forth that sounds genuinely conversational, not templated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ðŸ“š Appendix: Try More Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try with different Wikipedia articles!\n",
        "\n",
        "EXAMPLE_URLS = [\n",
        "    \"https://en.wikipedia.org/wiki/Mumbai_Indians\",\n",
        "    \"https://en.wikipedia.org/wiki/Artificial_intelligence\",\n",
        "    \"https://en.wikipedia.org/wiki/Shah_Rukh_Khan\",\n",
        "    \"https://en.wikipedia.org/wiki/Indian_Premier_League\",\n",
        "    \"https://en.wikipedia.org/wiki/Chandrayaan-3\",\n",
        "]\n",
        "\n",
        "print(\"ðŸŽ¯ Example Wikipedia URLs to try:\")\n",
        "for i, url in enumerate(EXAMPLE_URLS, 1):\n",
        "    title = url.split('/')[-1].replace('_', ' ')\n",
        "    print(f\"  {i}. {title}\")\n",
        "    print(f\"     {url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.5 Data Models"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
